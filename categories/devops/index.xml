<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>DevOps on Giulio Vian's Blog!</title><link>http://blog.casavian.eu/categories/devops/</link><description>Recent content in DevOps on Giulio Vian's Blog!</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><copyright>This work is licensed under a Creative Commons Attribution 4.0 International License</copyright><lastBuildDate>Mon, 23 Sep 2019 00:00:00 +0000</lastBuildDate><atom:link href="http://blog.casavian.eu/categories/devops/index.xml" rel="self" type="application/rss+xml"/><item><title>Using GitVersion in GitHub Actions beta</title><link>http://blog.casavian.eu/2019/09/23/using-gitversion-in-github-actions-beta/</link><pubDate>Mon, 23 Sep 2019 00:00:00 +0000</pubDate><guid>http://blog.casavian.eu/2019/09/23/using-gitversion-in-github-actions-beta/</guid><description>I was lucky to enter the GitHub Actions beta program so I wondered about the best way to test it. Finally, I decided to port Aggregator CLI &amp;nbsp; build scripts to GitHub Actions.
A critical step of those scripts is to run GitVersion &amp;nbsp; to generate the version for Aggregator. GitVersion, in the words of its authors, &amp;ldquo;looks at your git history and works out the semantic version of the commit being built.</description></item><item><title>Meta-pipelines - Part 5 - Automating the Host Environment</title><link>http://blog.casavian.eu/2019/09/20/meta-pipelines-part-5-automating-the-host-environment/</link><pubDate>Fri, 20 Sep 2019 00:00:00 +0000</pubDate><guid>http://blog.casavian.eu/2019/09/20/meta-pipelines-part-5-automating-the-host-environment/</guid><description>Looking back at the previous parts of this series, we have been able to manually setup two hosts, a Windows one and a Linux one, and a simple pipeline to automatically deploy new Azure DevOps/TFS Agents in Docker containers on such hosts and even update them.
In this post we will look how to provision the hosts themselves. For this purpose we will use Terraform and invoke it from Azure Pipelines so we can automate host creation in Azure.</description></item><item><title>Meta-pipelines - Part 4 - Deploy and Run</title><link>http://blog.casavian.eu/2019/09/13/meta-pipelines-part-4-deploy-and-run/</link><pubDate>Fri, 13 Sep 2019 00:00:00 +0000</pubDate><guid>http://blog.casavian.eu/2019/09/13/meta-pipelines-part-4-deploy-and-run/</guid><description>In the previous instalment we built custom Docker images for Azure Pipelines/TFS Agents. In this post, we will explore the lifecycle of Docker containers running such images.
Container Deploy Pipeline This pipeline is more complex than the previous requiring 4 actions:
checking if the agent (rectius the container running the agent) is running If so, stop and remove the container Pulling the image from the selected Docker Registry Starting the container with the proper parameters.</description></item><item><title>Meta-pipelines - Part 3 - Build and Registry</title><link>http://blog.casavian.eu/2019/09/06/meta-pipelines-part-3-build-and-registry/</link><pubDate>Fri, 06 Sep 2019 00:00:00 +0000</pubDate><guid>http://blog.casavian.eu/2019/09/06/meta-pipelines-part-3-build-and-registry/</guid><description>In the previous instalments we examined a possible Dockerfile for an Azure Pipelines/TFS Agent. In this post, we will explore the pipeline that can automatically build such custom agent images.
Docker Registry To automate properly we need a Docker Registry where storing the Docker images we build. There are many advantages in using a registry, in our scenario it enables:
pulling an image version built years ago distribution of images to multiple hosts caching locally base images, allowing air gap builds For the purpose of this series we will use Azure Container Registry (ACR for short), but there are many options; for example I used successfully ProGet &amp;nbsp; .</description></item><item><title>Meta-pipelines - Part 2 - Dockerize the agent</title><link>http://blog.casavian.eu/2019/08/30/meta-pipelines-part-2-dockerize-the-agent/</link><pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate><guid>http://blog.casavian.eu/2019/08/30/meta-pipelines-part-2-dockerize-the-agent/</guid><description>In the previous instalment we setup a couple of machines to run Docker and host docker containers. In this post, we will explore the structure of a Dockerfile for Azure Pipelines/TFS Agent.
There is a notable difference between Azure DevOps Service and Server in terms of handling agent updates. The first part of this article can be used in air-gapped environments.
If you need a primer on Docker there is plenty of resources, from the excellent The Docker Book &amp;nbsp; to the official documentation &amp;nbsp; , Pluralsight courses, etc.</description></item><item><title>Meta-pipelines - Part 1 - Docker Hosts</title><link>http://blog.casavian.eu/2019/08/23/meta-pipelines-part-1-docker-hosts/</link><pubDate>Fri, 23 Aug 2019 00:00:00 +0000</pubDate><guid>http://blog.casavian.eu/2019/08/23/meta-pipelines-part-1-docker-hosts/</guid><description>The first step will be to setup an environment where we can run Docker and is the topic for this instalment.
We need at least two kinds of hosts: a Windows and a Linux machines. Simple reason: you cannot run Windows containers on a Linux host, also running Linux containers on a Windows machine is inefficient (they truly run inside a virtual machine). Windows support for Docker is tied to specific kernel versions.</description></item><item><title>Meta-pipelines - Introduction</title><link>http://blog.casavian.eu/2019/08/19/meta-pipelines-introduction/</link><pubDate>Mon, 19 Aug 2019 00:00:00 +0000</pubDate><guid>http://blog.casavian.eu/2019/08/19/meta-pipelines-introduction/</guid><description>Welcome. This series of articles will go in details of automating Azure Pipelines infrastructure itself. The text is accompanied by a source code repository &amp;nbsp; publicly available on GitHub.
Scenario and Problems Imagine yourself in the scenario of an independent team responsible of maintaining its own build pipeline. Typical solutions are:
Grab a leftover desktop or server machine Ask the IT department for a virtual machine Buy a VM in the cloud Use the standard hosted agents provided by Azure Pipelines These solutions share some common problems.</description></item><item><title>Automate publishing documentation using Hugo and GitHub pages</title><link>http://blog.casavian.eu/2017/03/07/automate-publishing-documentation-using-hugo-and-github-pages/</link><pubDate>Tue, 07 Mar 2017 00:00:00 +0000</pubDate><guid>http://blog.casavian.eu/2017/03/07/automate-publishing-documentation-using-hugo-and-github-pages/</guid><description>Many of you knows my work on TFS Aggregator &amp;nbsp; . Since the beginning we opted for Markdown &amp;nbsp; as the format for the project documentation, at the beginning they were some files in a doc folder, then I moved the content to the project&amp;rsquo;s GitHub Wiki, today I use the same files to generate the GitHub pages at https://tfsaggregator.github.io/intro/.
In this post I will describe how this latter step works in detail to publish our open source project&amp;rsquo;s documentation.</description></item></channel></rss>